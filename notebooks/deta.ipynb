{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deta import Deta\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# initialize with a project key\n",
    "deta = Deta(os.environ.get(\"DETA_PROJECT_KEY\"))\n",
    "\n",
    "# create and use as many Drives as you want!\n",
    "forecasts = deta.Drive(\"forecasts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': ['test.csv', 'verticaltbs.csv']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  2\n",
       "2  3\n",
       "3  4\n",
       "4  5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([1,2,3,4,5])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test.csv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts.put('test.csv', path='test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': ['test.csv']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verticaltbs.csv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts.put('verticaltbs.csv', path='../forecasts/verticalTBS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': ['test.csv', 'verticaltbs.csv']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-0.21.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-0.21.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Downloading registry model 'daily-visits', version '1.0.0', stage None from workspace 'drdevinhopkins'...\n",
      "COMET INFO: Unzipping model to '/Users/devinhopkins/Dropbox/Code/hourly-report-neuralprophet/comet-ml-models' ...\n",
      "COMET INFO: done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet, set_log_level, load\n",
    "import comet_ml\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "comet_ml_api_key = os.environ.get(\"COMET_ML_API_KEY\")\n",
    "api = comet_ml.api.API(comet_ml_api_key)\n",
    "\n",
    "api.download_registry_model(\"drdevinhopkins\", \"daily-visits\",\n",
    "                            version=\"1.0.0\", output_path=\"../comet-ml-models\", expand=True, stage=None)\n",
    "\n",
    "set_log_level(\"ERROR\")\n",
    "\n",
    "loaded_model = load(\"../comet-ml-models/daily-visits.np\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/drdevinhopkins/hourly-report/main/data/daily-visits.csv')\n",
    "df.ds = pd.to_datetime(df.ds)\n",
    "df = df.sort_values(by='ds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\n you tried to log -1 which is currently not supported. Try a dict or a scalar/tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/loggers/tensorboard.py:232\u001b[0m, in \u001b[0;36mTensorBoardLogger.log_metrics\u001b[0;34m(self, metrics, step)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperiment\u001b[39m.\u001b[39madd_scalar(k, v, step)\n\u001b[1;32m    233\u001b[0m \u001b[39m# todo: specify the possible exception\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/loggers/logger.py:54\u001b[0m, in \u001b[0;36mrank_zero_experiment.<locals>.experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m get_experiment() \u001b[39mor\u001b[39;00m DummyExperiment()\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/utilities/rank_zero.py:32\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m rank_zero_only\u001b[39m.\u001b[39mrank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/loggers/logger.py:52\u001b[0m, in \u001b[0;36mrank_zero_experiment.<locals>.experiment.<locals>.get_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m@rank_zero_only\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_experiment\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Callable:\n\u001b[0;32m---> 52\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/loggers/tensorboard.py:175\u001b[0m, in \u001b[0;36mTensorBoardLogger.experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_dir:\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fs\u001b[39m.\u001b[39;49mmakedirs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot_dir, exist_ok\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    176\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experiment \u001b[39m=\u001b[39m SummaryWriter(log_dir\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_dir, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/fsspec/implementations/local.py:54\u001b[0m, in \u001b[0;36mLocalFileSystem.makedirs\u001b[0;34m(self, path, exist_ok)\u001b[0m\n\u001b[1;32m     53\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strip_protocol(path)\n\u001b[0;32m---> 54\u001b[0m os\u001b[39m.\u001b[39;49mmakedirs(path, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     makedirs(head, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n\u001b[1;32m    216\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     \u001b[39m# Defeats race condition when another thread created the path\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     makedirs(head, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n\u001b[1;32m    216\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     \u001b[39m# Defeats race condition when another thread created the path\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: makedirs at line 215 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     makedirs(head, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n\u001b[1;32m    216\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     \u001b[39m# Defeats race condition when another thread created the path\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 45] Operation not supported: '/home/runner'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m future \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39mmake_future_dataframe(df, periods\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m forecast \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39;49mpredict(future)\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/neuralprophet/forecaster.py:893\u001b[0m, in \u001b[0;36mNeuralProphet.predict\u001b[0;34m(self, df, decompose, raw)\u001b[0m\n\u001b[1;32m    891\u001b[0m forecast \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m    892\u001b[0m \u001b[39mfor\u001b[39;00m df_name, df_i \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mgroupby(\u001b[39m\"\u001b[39m\u001b[39mID\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m     dates, predicted, components \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_raw(df_i, df_name, include_components\u001b[39m=\u001b[39;49mdecompose)\n\u001b[1;32m    894\u001b[0m     df_i \u001b[39m=\u001b[39m df_utils\u001b[39m.\u001b[39mdrop_missing_from_df(\n\u001b[1;32m    895\u001b[0m         df_i, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig_missing\u001b[39m.\u001b[39mdrop_missing, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_steps, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_lags\n\u001b[1;32m    896\u001b[0m     )\n\u001b[1;32m    897\u001b[0m     \u001b[39mif\u001b[39;00m raw:\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/neuralprophet/forecaster.py:2938\u001b[0m, in \u001b[0;36mNeuralProphet._predict_raw\u001b[0;34m(self, df, df_name, include_components)\u001b[0m\n\u001b[1;32m   2936\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mset_compute_components(include_components)\n\u001b[1;32m   2937\u001b[0m \u001b[39m# Compute the predictions and components (if requested)\u001b[39;00m\n\u001b[0;32m-> 2938\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mpredict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, loader)\n\u001b[1;32m   2939\u001b[0m \u001b[39m# Extract the prediction and components\u001b[39;00m\n\u001b[1;32m   2940\u001b[0m predicted, component_vectors \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mresult)\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:949\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[39mRun inference on your data.\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[39mThis will call the model forward function to compute predictions. Useful to perform distributed\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[39m    Returns a list of dictionaries, one for each provided dataloader containing their respective predictions.\u001b[39;00m\n\u001b[1;32m    947\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module\n\u001b[0;32m--> 949\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_impl, model, dataloaders, datamodule, return_predictions, ckpt_path\n\u001b[1;32m    951\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    649\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    651\u001b[0m \u001b[39m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:996\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    991\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39mmodel_provided, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    992\u001b[0m )\n\u001b[1;32m    994\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predicted_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt_path  \u001b[39m# TODO: remove in v1.8\u001b[39;00m\n\u001b[0;32m--> 996\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    998\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    999\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1154\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_fit_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_lightning_module_hook(\u001b[39m\"\u001b[39m\u001b[39mon_fit_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1154\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_hyperparams()\n\u001b[1;32m   1156\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mrestore_checkpoint_after_setup:\n\u001b[1;32m   1157\u001b[0m     log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: restoring module and callbacks from checkpoint path: \u001b[39m\u001b[39m{\u001b[39;00mckpt_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1222\u001b[0m, in \u001b[0;36mTrainer._log_hyperparams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39mfor\u001b[39;00m logger \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloggers:\n\u001b[1;32m   1221\u001b[0m     \u001b[39mif\u001b[39;00m hparams_initial \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1222\u001b[0m         logger\u001b[39m.\u001b[39;49mlog_hyperparams(hparams_initial)\n\u001b[1;32m   1223\u001b[0m     logger\u001b[39m.\u001b[39mlog_graph(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module)\n\u001b[1;32m   1224\u001b[0m     logger\u001b[39m.\u001b[39msave()\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/utilities/rank_zero.py:32\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Any]:\n\u001b[1;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m rank_zero_only\u001b[39m.\u001b[39mrank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/loggers/tensorboard.py:211\u001b[0m, in \u001b[0;36mTensorBoardLogger.log_hyperparams\u001b[0;34m(self, params, metrics)\u001b[0m\n\u001b[1;32m    208\u001b[0m     metrics \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mhp_metric\u001b[39m\u001b[39m\"\u001b[39m: metrics}\n\u001b[1;32m    210\u001b[0m \u001b[39mif\u001b[39;00m metrics:\n\u001b[0;32m--> 211\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_metrics(metrics, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m    212\u001b[0m     exp, ssi, sei \u001b[39m=\u001b[39m hparams(params, metrics)\n\u001b[1;32m    213\u001b[0m     writer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperiment\u001b[39m.\u001b[39m_get_file_writer()\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/utilities/rank_zero.py:32\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Any]:\n\u001b[1;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m rank_zero_only\u001b[39m.\u001b[39mrank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/neuralprophet/logger.py:29\u001b[0m, in \u001b[0;36mMetricsLogger.log_metrics\u001b[0;34m(self, metrics, step)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39m@rank_zero_only\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_metrics\u001b[39m(\u001b[39mself\u001b[39m, metrics: Mapping[\u001b[39mstr\u001b[39m, \u001b[39mfloat\u001b[39m], step: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[39msuper\u001b[39;49m(MetricsLogger, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlog_metrics(metrics, step)\n\u001b[1;32m     30\u001b[0m     \u001b[39m# metrics is a dictionary of metric names and values\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[39mfor\u001b[39;00m metric_name, metric_value \u001b[39min\u001b[39;00m metrics\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/utilities/rank_zero.py:32\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Any]:\n\u001b[1;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m rank_zero_only\u001b[39m.\u001b[39mrank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/23-01-17/lib/python3.9/site-packages/pytorch_lightning/loggers/tensorboard.py:236\u001b[0m, in \u001b[0;36mTensorBoardLogger.log_metrics\u001b[0;34m(self, metrics, step)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m    235\u001b[0m     m \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m you tried to log \u001b[39m\u001b[39m{\u001b[39;00mv\u001b[39m}\u001b[39;00m\u001b[39m which is currently not supported. Try a dict or a scalar/tensor.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 236\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(m) \u001b[39mfrom\u001b[39;00m \u001b[39mex\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: \n you tried to log -1 which is currently not supported. Try a dict or a scalar/tensor."
     ]
    }
   ],
   "source": [
    "\n",
    "future = loaded_model.make_future_dataframe(df, periods=8)\n",
    "\n",
    "\n",
    "\n",
    "forecast = loaded_model.predict(future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forecast_trimmed = forecast[forecast.y.isnull()].set_index('ds')\n",
    "forecast_trimmed.to_csv('forecasts/daily_visits_raw.csv')\n",
    "\n",
    "start = forecast_trimmed.index.tolist()[0]\n",
    "forecast_length = len(forecast_trimmed.index.tolist())\n",
    "i = 0\n",
    "timestamp = pd.Timestamp.now().round('S').replace(tzinfo=None)\n",
    "forecast_output_list = []\n",
    "for ds in pd.date_range(start=start, periods=forecast_length, freq='D'):\n",
    "    i = i+1\n",
    "    forecast_output_list.append(\n",
    "        {'ds': ds, 'visits': forecast_trimmed.loc[ds]['yhat'+str(i)], 'timestamp': timestamp})\n",
    "forecast_output = pd.DataFrame(forecast_output_list)\n",
    "forecast_output.to_csv('forecasts/daily_visits.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/drdevinhopkins/daily-visits/0c8895e6816f44f28640ead1b0963728\n",
      "\n",
      "Finding best initial lr: 100%|███████████████| 240/240 [00:02<00:00, 108.27it/s]\n",
      "Missing logger folder: /Users/devinhopkins/Dropbox/Code/hourly-report-neuralprophet/notebooks/lightning_logs\n",
      "Epoch 131: 100%|█| 131/131 [00:00<00:00, 156.75it/s, loss=0.0053, v_num=0, MAE=1\n",
      "           MAE       RMSE      Loss  RegLoss  epoch\n",
      "130  13.984174  18.121597  0.005373      0.0    130\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/devinhopkins/Dropbox/Code/hourly-report-neuralprophet/notebooks/../scripts/create_daily_visits_model.py\", line 50, in <module>\n",
      "    save(m, \"models/daily-visits.np\")\n",
      "  File \"/Users/devinhopkins/anaconda3/envs/23-01-17/lib/python3.9/site-packages/neuralprophet/utils.py\", line 44, in save\n",
      "    torch.save(forecaster, path)\n",
      "  File \"/Users/devinhopkins/anaconda3/envs/23-01-17/lib/python3.9/site-packages/torch/serialization.py\", line 422, in save\n",
      "    with _open_zipfile_writer(f) as opened_zipfile:\n",
      "  File \"/Users/devinhopkins/anaconda3/envs/23-01-17/lib/python3.9/site-packages/torch/serialization.py\", line 309, in _open_zipfile_writer\n",
      "    return container(name_or_buffer)\n",
      "  File \"/Users/devinhopkins/anaconda3/envs/23-01-17/lib/python3.9/site-packages/torch/serialization.py\", line 287, in __init__\n",
      "    super(_open_zipfile_writer_file, self).__init__(torch._C.PyTorchFileWriter(str(name)))\n",
      "RuntimeError: Parent directory models does not exist.\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/drdevinhopkins/daily-visits/0c8895e6816f44f28640ead1b0963728\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     Loss [132]  : (0.00537338200956583, 1.6998523473739624)\n",
      "COMET INFO:     MAE [132]   : (13.984173774719238, 259.9486083984375)\n",
      "COMET INFO:     RMSE [132]  : (18.11304473876953, 329.2165832519531)\n",
      "COMET INFO:     RegLoss     : 0.0\n",
      "COMET INFO:     epoch [132] : (0, 130)\n",
      "COMET INFO:     hp_metric   : -1\n",
      "COMET INFO:     loss [1622] : (0.0031932552810758352, 2.1115756034851074)\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     changepoints_range : 0.95\n",
      "COMET INFO:     n_changepoints     : 50\n",
      "COMET INFO:     n_forecasts        : 12\n",
      "COMET INFO:     n_lags             : 4\n",
      "COMET INFO:     quantiles          : [0.2, 0.5, 0.8]\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     conda-environment-definition : 1\n",
      "COMET INFO:     conda-info                   : 1\n",
      "COMET INFO:     conda-specification          : 1\n",
      "COMET INFO:     environment details          : 1\n",
      "COMET INFO:     filename                     : 1\n",
      "COMET INFO:     git metadata                 : 1\n",
      "COMET INFO:     git-patch (uncompressed)     : 1 (319.63 KB)\n",
      "COMET INFO:     installed packages           : 1\n",
      "COMET INFO:     model graph                  : 1\n",
      "COMET INFO:     source_code                  : 1 (1.55 KB)\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "!python ../scripts/create_daily_visits_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "23-01-17",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e38f40ce2cd8aa953a8c19cf15acc093b5fddc4c20c85fcfa3d05ad81474f01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
