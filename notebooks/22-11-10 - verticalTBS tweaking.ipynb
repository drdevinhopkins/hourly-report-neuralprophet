{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/drdevinhopkins/verticaltbs-tweaking-hidden-layers/a05129c419a047a8bfd767c782a6cbe1\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/codespace/.local/lib/python3.10/site-packages/neuralprophet/df_utils.py:1036: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, \"ds\"] = pd.to_datetime(df.loc[:, \"ds\"])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/codespace/.local/lib/python3.10/site-packages/neuralprophet/df_utils.py:1036: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, \"ds\"] = pd.to_datetime(df.loc[:, \"ds\"])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/codespace/.local/lib/python3.10/site-packages/neuralprophet/df_utils.py:1036: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, \"ds\"] = pd.to_datetime(df.loc[:, \"ds\"])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/codespace/.local/lib/python3.10/site-packages/neuralprophet/df_utils.py:193: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, \"ds\"] = pd.to_datetime(df.loc[:, \"ds\"])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/codespace/.local/lib/python3.10/site-packages/neuralprophet/df_utils.py:193: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, \"ds\"] = pd.to_datetime(df.loc[:, \"ds\"])\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6150a9be1343c3baa1a23f00d84fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /home/codespace/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:928: UserWarning: Using a target size (torch.Size([64, 12, 1])) that is different to the input size (torch.Size([64, 12, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/codespace/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:928: UserWarning: Using a target size (torch.Size([318, 12, 1])) that is different to the input size (torch.Size([318, 12, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2922bca5a9e44762b90764e13b16b271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------                                                                                                                                              \n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/drdevinhopkins/verticaltbs-tweaking-hidden-layers/a05129c419a047a8bfd767c782a6cbe1\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     Loss             : 0.02137163043329235\n",
      "COMET INFO:     MAE              : 3.7003215699775045\n",
      "COMET INFO:     MAE_val          : 5.3952185397897825\n",
      "COMET INFO:     RMSE             : 4.840660240511485\n",
      "COMET INFO:     RMSE_val         : 6.933195044493923\n",
      "COMET INFO:     RegLoss          : 0.0\n",
      "COMET INFO:     SmoothL1Loss     : 0.01499717800100049\n",
      "COMET INFO:     SmoothL1Loss_val : 0.030716458512418096\n",
      "COMET INFO:     loss [3088]      : (0.01610429398715496, 284.8525695800781)\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     daily_seasonality  : True\n",
      "COMET INFO:     n_forecasts        : 12\n",
      "COMET INFO:     n_lags             : 17\n",
      "COMET INFO:     num_hidden_layers  : 0\n",
      "COMET INFO:     quantiles          : [0.2, 0.5, 0.8]\n",
      "COMET INFO:     weekly_seasonality : True\n",
      "COMET INFO:     yearly_seasonality : False\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (21.66 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: ---------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SmoothL1Loss       MAE     RMSE      Loss  RegLoss  SmoothL1Loss_val  \\\n",
      "81      0.014997  3.700322  4.84066  0.021372      0.0          0.030716   \n",
      "\n",
      "     MAE_val  RMSE_val  \n",
      "81  5.395219  6.933195  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET ERROR: Error sending a notification, make sure you have opted-in for notifications\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "from comet_ml.api import API, APIExperiment\n",
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet, set_log_level, save, set_random_seed\n",
    "import pickle\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "# api = API(os.environ.get('COMET_ML_API_KEY'))\n",
    "api = API('IbXp3DT5kVkFPKwnzhg3mgUTL')\n",
    "\n",
    "set_log_level(\"CRITICAL\")\n",
    "set_random_seed(221110)\n",
    "\n",
    "target_column = 'Total Vertical TBS'\n",
    "\n",
    "df = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/drdevinhopkins/hourly-report/main/data/since-2020.csv')\n",
    "df.ds = pd.to_datetime(df.ds)\n",
    "df = df.drop(['Date', 'Time'], axis=1)\n",
    "df = df.sort_values(by='ds', ascending=True)\n",
    "df.rename(columns={target_column: 'y', 'Adm. requests cum': \"Adm requests cum\",\n",
    "          'Pts.waiting for admission CUM': 'Pts waiting for admission CUM'}, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "regressors = df.columns.tolist()\n",
    "regressors.remove('y')\n",
    "regressors.remove('ds')\n",
    "\n",
    "for param in [0]:\n",
    "\n",
    "    experiment = Experiment(\n",
    "    # api_key=os.environ.get('COMET_ML_API_KEY'),\n",
    "    api_key='IbXp3DT5kVkFPKwnzhg3mgUTL',\n",
    "    project_name=\"verticalTBS-tweaking-hidden-layers\",\n",
    "    workspace=\"drdevinhopkins\",\n",
    ")\n",
    "\n",
    "    params = {\n",
    "        # growth='off',\n",
    "        'yearly_seasonality': False,\n",
    "        'weekly_seasonality': True,\n",
    "        'daily_seasonality': True,\n",
    "        'n_lags': 17,\n",
    "        'n_forecasts': 12,\n",
    "        # 'changepoints_range': 0.95,\n",
    "        # 'n_changepoints': 50,\n",
    "        'quantiles': [0.2, 0.5, 0.8],\n",
    "        # 'num_hidden_layers':0\n",
    "        # d_hidden=36,\n",
    "        # learning_rate=0.005,\n",
    "    }\n",
    "\n",
    "    m = NeuralProphet(**params)\n",
    "    m = m.add_lagged_regressor(names=regressors)\n",
    "    m = m.add_country_holidays(\"CA\")\n",
    "    df_train, df_test = m.split_df(df, valid_p=0.05)\n",
    "\n",
    "    metrics = m.fit(df_train,\n",
    "                    freq='H',\n",
    "                    validation_df=df_test\n",
    "                    # progress='plot'\n",
    "                    )\n",
    "    print(metrics.tail(1))\n",
    "\n",
    "    experiment.log_parameters(params)\n",
    "    experiment.log_metrics(metrics.tail(1).iloc[0].to_dict())\n",
    "\n",
    "    experiment.end()\n",
    "\n",
    "    clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /home/codespace/.local/lib/python3.10/site-packages/neuralprophet/df_utils.py:1036: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, \"ds\"] = pd.to_datetime(df.loc[:, \"ds\"])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/codespace/.local/lib/python3.10/site-packages/neuralprophet/df_utils.py:1036: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, \"ds\"] = pd.to_datetime(df.loc[:, \"ds\"])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/codespace/.local/lib/python3.10/site-packages/neuralprophet/df_utils.py:193: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, \"ds\"] = pd.to_datetime(df.loc[:, \"ds\"])\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Encountered variable with singular value in training set. Please remove variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mfor\u001b[39;00m df_train, df_test \u001b[39min\u001b[39;00m folds:\n\u001b[1;32m     44\u001b[0m     m \u001b[39m=\u001b[39m NeuralProphet(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\u001b[39m.\u001b[39madd_lagged_regressor(names\u001b[39m=\u001b[39mregressors)\u001b[39m.\u001b[39madd_country_holidays(\u001b[39m\"\u001b[39m\u001b[39mCA\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m     train \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39;49mfit(df\u001b[39m=\u001b[39;49mdf_train, freq\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mH\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     46\u001b[0m     test \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mtest(df\u001b[39m=\u001b[39mdf_test)\n\u001b[1;32m     47\u001b[0m     metrics_train \u001b[39m=\u001b[39m metrics_train\u001b[39m.\u001b[39mappend(train[METRICS]\u001b[39m.\u001b[39miloc[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/neuralprophet/forecaster.py:669\u001b[0m, in \u001b[0;36mNeuralProphet.fit\u001b[0;34m(self, df, freq, validation_df, progress, minimal)\u001b[0m\n\u001b[1;32m    667\u001b[0m         metrics_df \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    668\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         metrics_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(df, progress\u001b[39m=\u001b[39;49mprogress)\n\u001b[1;32m    670\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    671\u001b[0m     df_val, _, _, _ \u001b[39m=\u001b[39m df_utils\u001b[39m.\u001b[39mprep_or_copy_df(validation_df)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/neuralprophet/forecaster.py:2360\u001b[0m, in \u001b[0;36mNeuralProphet._train\u001b[0;34m(self, df, df_val, progress)\u001b[0m\n\u001b[1;32m   2357\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_minimal(df, progress_bar\u001b[39m=\u001b[39mprogress_bar)\n\u001b[1;32m   2359\u001b[0m \u001b[39m# set up data loader\u001b[39;00m\n\u001b[0;32m-> 2360\u001b[0m loader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_train_loader(df)\n\u001b[1;32m   2361\u001b[0m \u001b[39m# set up Metrics\u001b[39;00m\n\u001b[1;32m   2362\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhighlight_forecast_step_n \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/neuralprophet/forecaster.py:2112\u001b[0m, in \u001b[0;36mNeuralProphet._init_train_loader\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m   2110\u001b[0m df, _, _, _ \u001b[39m=\u001b[39m df_utils\u001b[39m.\u001b[39mprep_or_copy_df(df)\n\u001b[1;32m   2111\u001b[0m \u001b[39m# if not self.fitted:\u001b[39;00m\n\u001b[0;32m-> 2112\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_normalization\u001b[39m.\u001b[39;49minit_data_params(\n\u001b[1;32m   2113\u001b[0m     df\u001b[39m=\u001b[39;49mdf,\n\u001b[1;32m   2114\u001b[0m     config_covariates\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_covar,\n\u001b[1;32m   2115\u001b[0m     config_regressor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_regressors,\n\u001b[1;32m   2116\u001b[0m     config_events\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_events,\n\u001b[1;32m   2117\u001b[0m )\n\u001b[1;32m   2119\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_normalize(df)\n\u001b[1;32m   2120\u001b[0m \u001b[39m# if not self.fitted:\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/neuralprophet/configure.py:42\u001b[0m, in \u001b[0;36mNormalization.init_data_params\u001b[0;34m(self, df, config_covariates, config_regressor, config_events)\u001b[0m\n\u001b[1;32m     40\u001b[0m         log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mSetting normalization to global as only one dataframe provided for training.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_normalization \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_data_params, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_data_params \u001b[39m=\u001b[39m df_utils\u001b[39m.\u001b[39;49minit_data_params(\n\u001b[1;32m     43\u001b[0m     df\u001b[39m=\u001b[39;49mdf,\n\u001b[1;32m     44\u001b[0m     normalize\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize,\n\u001b[1;32m     45\u001b[0m     config_covariates\u001b[39m=\u001b[39;49mconfig_covariates,\n\u001b[1;32m     46\u001b[0m     config_regressor\u001b[39m=\u001b[39;49mconfig_regressor,\n\u001b[1;32m     47\u001b[0m     config_events\u001b[39m=\u001b[39;49mconfig_events,\n\u001b[1;32m     48\u001b[0m     global_normalization\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mglobal_normalization,\n\u001b[1;32m     49\u001b[0m     global_time_normalization\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mglobal_normalization,\n\u001b[1;32m     50\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/neuralprophet/df_utils.py:293\u001b[0m, in \u001b[0;36minit_data_params\u001b[0;34m(df, normalize, config_covariates, config_regressor, config_events, global_normalization, global_time_normalization)\u001b[0m\n\u001b[1;32m    291\u001b[0m df, _, _, _ \u001b[39m=\u001b[39m prep_or_copy_df(df)\n\u001b[1;32m    292\u001b[0m df_merged \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mdrop(\u001b[39m\"\u001b[39m\u001b[39mID\u001b[39m\u001b[39m\"\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 293\u001b[0m global_data_params \u001b[39m=\u001b[39m data_params_definition(\n\u001b[1;32m    294\u001b[0m     df_merged, normalize, config_covariates, config_regressor, config_events\n\u001b[1;32m    295\u001b[0m )\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m global_normalization:\n\u001b[1;32m    297\u001b[0m     log\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    298\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGlobal Normalization Data Parameters (shift, scale): \u001b[39m\u001b[39m{\u001b[39;00m[(k, v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m global_data_params\u001b[39m.\u001b[39mitems()]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/neuralprophet/df_utils.py:208\u001b[0m, in \u001b[0;36mdata_params_definition\u001b[0;34m(df, normalize, config_covariates, config_regressor, config_events)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[39mif\u001b[39;00m covar \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns:\n\u001b[1;32m    207\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCovariate \u001b[39m\u001b[39m{\u001b[39;00mcovar\u001b[39m}\u001b[39;00m\u001b[39m not found in DataFrame.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 208\u001b[0m         data_params[covar] \u001b[39m=\u001b[39m get_normalization_params(\n\u001b[1;32m    209\u001b[0m             array\u001b[39m=\u001b[39;49mdf[covar]\u001b[39m.\u001b[39;49mvalues,\n\u001b[1;32m    210\u001b[0m             norm_type\u001b[39m=\u001b[39;49mconfig_covariates[covar]\u001b[39m.\u001b[39;49mnormalize,\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m config_regressor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m reg \u001b[39min\u001b[39;00m config_regressor\u001b[39m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/neuralprophet/df_utils.py:330\u001b[0m, in \u001b[0;36mget_normalization_params\u001b[0;34m(array, norm_type)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_normalization_params\u001b[39m(array, norm_type):\n\u001b[1;32m    329\u001b[0m     \u001b[39mif\u001b[39;00m norm_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 330\u001b[0m         norm_type \u001b[39m=\u001b[39m auto_normalization_setting(array)\n\u001b[1;32m    331\u001b[0m     shift \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m    332\u001b[0m     scale \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/neuralprophet/df_utils.py:320\u001b[0m, in \u001b[0;36mauto_normalization_setting\u001b[0;34m(array)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(array)) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    319\u001b[0m     log\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mEncountered variable with singular value in training set. Please remove variable.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 320\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEncountered variable with singular value in training set. Please remove variable.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    321\u001b[0m \u001b[39m# elif set(series.unique()) in ({True, False}, {1, 0}, {1.0, 0.0}, {-1, 1}, {-1.0, 1.0}):\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(array)) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Encountered variable with singular value in training set. Please remove variable."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet, set_log_level, save, set_random_seed\n",
    "\n",
    "set_log_level(\"CRITICAL\")\n",
    "set_random_seed(221110)\n",
    "\n",
    "target_column = 'Total Vertical TBS'\n",
    "\n",
    "df = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/drdevinhopkins/hourly-report/main/data/since-2020.csv')\n",
    "df.ds = pd.to_datetime(df.ds)\n",
    "df = df.drop(['Date', 'Time'], axis=1)\n",
    "df = df.sort_values(by='ds', ascending=True)\n",
    "df.rename(columns={target_column: 'y', 'Adm. requests cum': \"Adm requests cum\",\n",
    "          'Pts.waiting for admission CUM': 'Pts waiting for admission CUM'}, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "regressors = df.columns.tolist()\n",
    "regressors.remove('y')\n",
    "regressors.remove('ds')\n",
    "\n",
    "METRICS = [\"SmoothL1Loss\", \"MAE\", \"RMSE\"]\n",
    "\n",
    "params = {\n",
    "    # growth='off',\n",
    "    'yearly_seasonality': False,\n",
    "    'weekly_seasonality': True,\n",
    "    'daily_seasonality': True,\n",
    "    'n_lags': 17,\n",
    "    'n_forecasts': 12,\n",
    "    # 'changepoints_range': 0.95,\n",
    "    # 'n_changepoints': 50,\n",
    "    # 'quantiles': [0.2, 0.5, 0.8],\n",
    "    # 'num_hidden_layers':0\n",
    "    # d_hidden=36,\n",
    "    # learning_rate=0.005,\n",
    "}\n",
    "\n",
    "folds = NeuralProphet(**params).add_lagged_regressor(names=regressors).add_country_holidays(\"CA\").crossvalidation_split_df(df, freq=\"H\", k=5, fold_pct=0.20, fold_overlap_pct=0.5)\n",
    "\n",
    "metrics_train = pd.DataFrame(columns=METRICS)\n",
    "metrics_test = pd.DataFrame(columns=METRICS)\n",
    "\n",
    "for df_train, df_test in folds:\n",
    "    m = NeuralProphet(**params).add_lagged_regressor(names=regressors).add_country_holidays(\"CA\")\n",
    "    train = m.fit(df=df_train, freq='H')\n",
    "    test = m.test(df=df_test)\n",
    "    metrics_train = metrics_train.append(train[METRICS].iloc[-1])\n",
    "    metrics_test = metrics_test.append(test[METRICS].iloc[-1])\n",
    "\n",
    "metrics_test.describe().loc[[\"mean\", \"std\", \"min\", \"max\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stretcher Pts hrly',\n",
       " 'Stretcher Pts cum',\n",
       " 'Ambulatory Pts hrly',\n",
       " 'Ambulatory Pts cum',\n",
       " 'Total Inflow hrly',\n",
       " 'Total Inflow cum',\n",
       " 'Ambulances hrly',\n",
       " 'Ambulances cum',\n",
       " 'FLS hrly',\n",
       " 'Adm requests cum',\n",
       " 'Admissions cum',\n",
       " 'Pts waiting for admission CUM',\n",
       " 'Total Stretcher pts',\n",
       " 'Triage hallway pts',\n",
       " 'Triage hallway pts TBS',\n",
       " 'Re-Oriented Nurse cum',\n",
       " 'Re-Oriented MD QTrack D/C',\n",
       " 'Re-Oriented MD QTrack NotD/C',\n",
       " 'Resus Pts',\n",
       " 'Totalpts in PODs except Psych',\n",
       " 'Green Pts',\n",
       " 'Green Pts TBS',\n",
       " 'Yellow PTS',\n",
       " 'Yellow Pts TBS',\n",
       " 'Orancge Pts except psych',\n",
       " 'Orange Pts TBS',\n",
       " 'Consults > 2h in PODS except IM',\n",
       " 'Consult for IM >4h in PODS',\n",
       " 'Plain films reqs > 2 h in PODs',\n",
       " 'CTs reqs > 2 h in PODs',\n",
       " 'Post POD (Family room)',\n",
       " 'Stretcher Pts in Vertical',\n",
       " 'Stretcher Pts TBS in Vertical',\n",
       " 'Stretcher Pts in Vertical on Lazyboy',\n",
       " 'Vertical Pts Waiting for Results',\n",
       " 'Ambulatory Pts in Vertical',\n",
       " 'Ambulatory Pts TBS in Vertical',\n",
       " 'QTrack Patients TBS',\n",
       " 'GARAGE patient TBS',\n",
       " 'Consults > 2h in Vertical Except IM',\n",
       " 'Consult for IM >4h in Vertical',\n",
       " 'Plain films reqs > 2 hr in Vertical',\n",
       " 'CTs reqs > 2 hrs in Vertical',\n",
       " 'Psych Stretcher Pts1pt',\n",
       " 'Psych pts waiting for admission',\n",
       " 'Total Pod TBS']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
